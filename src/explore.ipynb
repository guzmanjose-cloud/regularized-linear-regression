{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>fips</th>\n",
                            "      <th>TOT_POP</th>\n",
                            "      <th>0-9</th>\n",
                            "      <th>0-9 y/o % of total pop</th>\n",
                            "      <th>19-Oct</th>\n",
                            "      <th>10-19 y/o % of total pop</th>\n",
                            "      <th>20-29</th>\n",
                            "      <th>20-29 y/o % of total pop</th>\n",
                            "      <th>30-39</th>\n",
                            "      <th>30-39 y/o % of total pop</th>\n",
                            "      <th>...</th>\n",
                            "      <th>COPD_number</th>\n",
                            "      <th>diabetes_prevalence</th>\n",
                            "      <th>diabetes_Lower 95% CI</th>\n",
                            "      <th>diabetes_Upper 95% CI</th>\n",
                            "      <th>diabetes_number</th>\n",
                            "      <th>CKD_prevalence</th>\n",
                            "      <th>CKD_Lower 95% CI</th>\n",
                            "      <th>CKD_Upper 95% CI</th>\n",
                            "      <th>CKD_number</th>\n",
                            "      <th>Urban_rural_code</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>1001</td>\n",
                            "      <td>55601</td>\n",
                            "      <td>6787</td>\n",
                            "      <td>12.206615</td>\n",
                            "      <td>7637</td>\n",
                            "      <td>13.735364</td>\n",
                            "      <td>6878</td>\n",
                            "      <td>12.370281</td>\n",
                            "      <td>7089</td>\n",
                            "      <td>12.749771</td>\n",
                            "      <td>...</td>\n",
                            "      <td>3644</td>\n",
                            "      <td>12.9</td>\n",
                            "      <td>11.9</td>\n",
                            "      <td>13.8</td>\n",
                            "      <td>5462</td>\n",
                            "      <td>3.1</td>\n",
                            "      <td>2.9</td>\n",
                            "      <td>3.3</td>\n",
                            "      <td>1326</td>\n",
                            "      <td>3</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>1003</td>\n",
                            "      <td>218022</td>\n",
                            "      <td>24757</td>\n",
                            "      <td>11.355276</td>\n",
                            "      <td>26913</td>\n",
                            "      <td>12.344167</td>\n",
                            "      <td>23579</td>\n",
                            "      <td>10.814964</td>\n",
                            "      <td>25213</td>\n",
                            "      <td>11.564429</td>\n",
                            "      <td>...</td>\n",
                            "      <td>14692</td>\n",
                            "      <td>12.0</td>\n",
                            "      <td>11.0</td>\n",
                            "      <td>13.1</td>\n",
                            "      <td>20520</td>\n",
                            "      <td>3.2</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>3.5</td>\n",
                            "      <td>5479</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1005</td>\n",
                            "      <td>24881</td>\n",
                            "      <td>2732</td>\n",
                            "      <td>10.980266</td>\n",
                            "      <td>2960</td>\n",
                            "      <td>11.896628</td>\n",
                            "      <td>3268</td>\n",
                            "      <td>13.134520</td>\n",
                            "      <td>3201</td>\n",
                            "      <td>12.865239</td>\n",
                            "      <td>...</td>\n",
                            "      <td>2373</td>\n",
                            "      <td>19.7</td>\n",
                            "      <td>18.6</td>\n",
                            "      <td>20.6</td>\n",
                            "      <td>3870</td>\n",
                            "      <td>4.5</td>\n",
                            "      <td>4.2</td>\n",
                            "      <td>4.8</td>\n",
                            "      <td>887</td>\n",
                            "      <td>6</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>1007</td>\n",
                            "      <td>22400</td>\n",
                            "      <td>2456</td>\n",
                            "      <td>10.964286</td>\n",
                            "      <td>2596</td>\n",
                            "      <td>11.589286</td>\n",
                            "      <td>3029</td>\n",
                            "      <td>13.522321</td>\n",
                            "      <td>3113</td>\n",
                            "      <td>13.897321</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1789</td>\n",
                            "      <td>14.1</td>\n",
                            "      <td>13.2</td>\n",
                            "      <td>14.9</td>\n",
                            "      <td>2511</td>\n",
                            "      <td>3.3</td>\n",
                            "      <td>3.1</td>\n",
                            "      <td>3.6</td>\n",
                            "      <td>595</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>1009</td>\n",
                            "      <td>57840</td>\n",
                            "      <td>7095</td>\n",
                            "      <td>12.266598</td>\n",
                            "      <td>7570</td>\n",
                            "      <td>13.087828</td>\n",
                            "      <td>6742</td>\n",
                            "      <td>11.656293</td>\n",
                            "      <td>6884</td>\n",
                            "      <td>11.901798</td>\n",
                            "      <td>...</td>\n",
                            "      <td>4661</td>\n",
                            "      <td>13.5</td>\n",
                            "      <td>12.6</td>\n",
                            "      <td>14.5</td>\n",
                            "      <td>6017</td>\n",
                            "      <td>3.4</td>\n",
                            "      <td>3.2</td>\n",
                            "      <td>3.7</td>\n",
                            "      <td>1507</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3135</th>\n",
                            "      <td>56037</td>\n",
                            "      <td>43051</td>\n",
                            "      <td>6104</td>\n",
                            "      <td>14.178532</td>\n",
                            "      <td>6326</td>\n",
                            "      <td>14.694200</td>\n",
                            "      <td>5359</td>\n",
                            "      <td>12.448027</td>\n",
                            "      <td>6577</td>\n",
                            "      <td>15.277229</td>\n",
                            "      <td>...</td>\n",
                            "      <td>2098</td>\n",
                            "      <td>8.9</td>\n",
                            "      <td>8.3</td>\n",
                            "      <td>9.6</td>\n",
                            "      <td>2834</td>\n",
                            "      <td>2.6</td>\n",
                            "      <td>2.4</td>\n",
                            "      <td>2.8</td>\n",
                            "      <td>821</td>\n",
                            "      <td>5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3136</th>\n",
                            "      <td>56039</td>\n",
                            "      <td>23081</td>\n",
                            "      <td>2384</td>\n",
                            "      <td>10.328842</td>\n",
                            "      <td>2185</td>\n",
                            "      <td>9.466661</td>\n",
                            "      <td>2967</td>\n",
                            "      <td>12.854729</td>\n",
                            "      <td>4093</td>\n",
                            "      <td>17.733200</td>\n",
                            "      <td>...</td>\n",
                            "      <td>928</td>\n",
                            "      <td>7.2</td>\n",
                            "      <td>6.5</td>\n",
                            "      <td>8.0</td>\n",
                            "      <td>1360</td>\n",
                            "      <td>2.4</td>\n",
                            "      <td>2.2</td>\n",
                            "      <td>2.6</td>\n",
                            "      <td>447</td>\n",
                            "      <td>5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3137</th>\n",
                            "      <td>56041</td>\n",
                            "      <td>20299</td>\n",
                            "      <td>3121</td>\n",
                            "      <td>15.375142</td>\n",
                            "      <td>3205</td>\n",
                            "      <td>15.788955</td>\n",
                            "      <td>2153</td>\n",
                            "      <td>10.606434</td>\n",
                            "      <td>2702</td>\n",
                            "      <td>13.311001</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1163</td>\n",
                            "      <td>10.4</td>\n",
                            "      <td>9.5</td>\n",
                            "      <td>11.2</td>\n",
                            "      <td>1500</td>\n",
                            "      <td>3.0</td>\n",
                            "      <td>2.8</td>\n",
                            "      <td>3.2</td>\n",
                            "      <td>430</td>\n",
                            "      <td>5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3138</th>\n",
                            "      <td>56043</td>\n",
                            "      <td>7885</td>\n",
                            "      <td>858</td>\n",
                            "      <td>10.881420</td>\n",
                            "      <td>1113</td>\n",
                            "      <td>14.115409</td>\n",
                            "      <td>715</td>\n",
                            "      <td>9.067850</td>\n",
                            "      <td>903</td>\n",
                            "      <td>11.452124</td>\n",
                            "      <td>...</td>\n",
                            "      <td>506</td>\n",
                            "      <td>11.3</td>\n",
                            "      <td>10.3</td>\n",
                            "      <td>12.1</td>\n",
                            "      <td>686</td>\n",
                            "      <td>3.4</td>\n",
                            "      <td>3.2</td>\n",
                            "      <td>3.7</td>\n",
                            "      <td>207</td>\n",
                            "      <td>6</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3139</th>\n",
                            "      <td>56045</td>\n",
                            "      <td>6967</td>\n",
                            "      <td>780</td>\n",
                            "      <td>11.195637</td>\n",
                            "      <td>779</td>\n",
                            "      <td>11.181283</td>\n",
                            "      <td>681</td>\n",
                            "      <td>9.774652</td>\n",
                            "      <td>906</td>\n",
                            "      <td>13.004162</td>\n",
                            "      <td>...</td>\n",
                            "      <td>480</td>\n",
                            "      <td>11.7</td>\n",
                            "      <td>10.7</td>\n",
                            "      <td>12.7</td>\n",
                            "      <td>644</td>\n",
                            "      <td>3.4</td>\n",
                            "      <td>3.1</td>\n",
                            "      <td>3.6</td>\n",
                            "      <td>185</td>\n",
                            "      <td>6</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>3140 rows × 108 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "       fips  TOT_POP    0-9  0-9 y/o % of total pop  19-Oct  \\\n",
                            "0      1001    55601   6787               12.206615    7637   \n",
                            "1      1003   218022  24757               11.355276   26913   \n",
                            "2      1005    24881   2732               10.980266    2960   \n",
                            "3      1007    22400   2456               10.964286    2596   \n",
                            "4      1009    57840   7095               12.266598    7570   \n",
                            "...     ...      ...    ...                     ...     ...   \n",
                            "3135  56037    43051   6104               14.178532    6326   \n",
                            "3136  56039    23081   2384               10.328842    2185   \n",
                            "3137  56041    20299   3121               15.375142    3205   \n",
                            "3138  56043     7885    858               10.881420    1113   \n",
                            "3139  56045     6967    780               11.195637     779   \n",
                            "\n",
                            "      10-19 y/o % of total pop  20-29  20-29 y/o % of total pop  30-39  \\\n",
                            "0                    13.735364   6878                 12.370281   7089   \n",
                            "1                    12.344167  23579                 10.814964  25213   \n",
                            "2                    11.896628   3268                 13.134520   3201   \n",
                            "3                    11.589286   3029                 13.522321   3113   \n",
                            "4                    13.087828   6742                 11.656293   6884   \n",
                            "...                        ...    ...                       ...    ...   \n",
                            "3135                 14.694200   5359                 12.448027   6577   \n",
                            "3136                  9.466661   2967                 12.854729   4093   \n",
                            "3137                 15.788955   2153                 10.606434   2702   \n",
                            "3138                 14.115409    715                  9.067850    903   \n",
                            "3139                 11.181283    681                  9.774652    906   \n",
                            "\n",
                            "      30-39 y/o % of total pop  ...  COPD_number  diabetes_prevalence  \\\n",
                            "0                    12.749771  ...         3644                 12.9   \n",
                            "1                    11.564429  ...        14692                 12.0   \n",
                            "2                    12.865239  ...         2373                 19.7   \n",
                            "3                    13.897321  ...         1789                 14.1   \n",
                            "4                    11.901798  ...         4661                 13.5   \n",
                            "...                        ...  ...          ...                  ...   \n",
                            "3135                 15.277229  ...         2098                  8.9   \n",
                            "3136                 17.733200  ...          928                  7.2   \n",
                            "3137                 13.311001  ...         1163                 10.4   \n",
                            "3138                 11.452124  ...          506                 11.3   \n",
                            "3139                 13.004162  ...          480                 11.7   \n",
                            "\n",
                            "      diabetes_Lower 95% CI  diabetes_Upper 95% CI  diabetes_number  \\\n",
                            "0                      11.9                   13.8             5462   \n",
                            "1                      11.0                   13.1            20520   \n",
                            "2                      18.6                   20.6             3870   \n",
                            "3                      13.2                   14.9             2511   \n",
                            "4                      12.6                   14.5             6017   \n",
                            "...                     ...                    ...              ...   \n",
                            "3135                    8.3                    9.6             2834   \n",
                            "3136                    6.5                    8.0             1360   \n",
                            "3137                    9.5                   11.2             1500   \n",
                            "3138                   10.3                   12.1              686   \n",
                            "3139                   10.7                   12.7              644   \n",
                            "\n",
                            "      CKD_prevalence  CKD_Lower 95% CI  CKD_Upper 95% CI  CKD_number  \\\n",
                            "0                3.1               2.9               3.3        1326   \n",
                            "1                3.2               3.0               3.5        5479   \n",
                            "2                4.5               4.2               4.8         887   \n",
                            "3                3.3               3.1               3.6         595   \n",
                            "4                3.4               3.2               3.7        1507   \n",
                            "...              ...               ...               ...         ...   \n",
                            "3135             2.6               2.4               2.8         821   \n",
                            "3136             2.4               2.2               2.6         447   \n",
                            "3137             3.0               2.8               3.2         430   \n",
                            "3138             3.4               3.2               3.7         207   \n",
                            "3139             3.4               3.1               3.6         185   \n",
                            "\n",
                            "      Urban_rural_code  \n",
                            "0                    3  \n",
                            "1                    4  \n",
                            "2                    6  \n",
                            "3                    2  \n",
                            "4                    2  \n",
                            "...                ...  \n",
                            "3135                 5  \n",
                            "3136                 5  \n",
                            "3137                 5  \n",
                            "3138                 6  \n",
                            "3139                 6  \n",
                            "\n",
                            "[3140 rows x 108 columns]"
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "file_path = \"https://raw.githubusercontent.com/4GeeksAcademy/regularized-linear-regression-project-tutorial/main/demographic_health_data.csv\"\n",
                "\n",
                "data = pd.read_csv(file_path)\n",
                "\n",
                "data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "fips                      False\n",
                        "TOT_POP                   False\n",
                        "0-9                       False\n",
                        "0-9 y/o % of total pop    False\n",
                        "19-Oct                    False\n",
                        "                          ...  \n",
                        "CKD_prevalence            False\n",
                        "CKD_Lower 95% CI          False\n",
                        "CKD_Upper 95% CI          False\n",
                        "CKD_number                False\n",
                        "Urban_rural_code          False\n",
                        "Length: 108, dtype: bool\n",
                        "shape: (3140, 108)\n",
                        "describe:                fips       TOT_POP           0-9  0-9 y/o % of total pop  \\\n",
                        "count   3140.000000  3.140000e+03  3.140000e+03             3140.000000   \n",
                        "mean   30401.640764  1.041894e+05  1.274030e+04               11.871051   \n",
                        "std    15150.559265  3.335834e+05  4.180730e+04                2.124081   \n",
                        "min     1001.000000  8.800000e+01  0.000000e+00                0.000000   \n",
                        "25%    18180.500000  1.096325e+04  1.280500e+03               10.594639   \n",
                        "50%    29178.000000  2.580050e+04  3.057000e+03               11.802727   \n",
                        "75%    45081.500000  6.791300e+04  8.097000e+03               12.951840   \n",
                        "max    56045.000000  1.010552e+07  1.208253e+06               25.460677   \n",
                        "\n",
                        "             19-Oct  10-19 y/o % of total pop         20-29  \\\n",
                        "count  3.140000e+03               3140.000000  3.140000e+03   \n",
                        "mean   1.336798e+04                 12.694609  1.446933e+04   \n",
                        "std    4.228439e+04                  1.815044  4.957773e+04   \n",
                        "min    0.000000e+00                  0.000000  0.000000e+00   \n",
                        "25%    1.374500e+03                 11.674504  1.263750e+03   \n",
                        "50%    3.274000e+03                 12.687422  3.108000e+03   \n",
                        "75%    8.822250e+03                 13.659282  8.976250e+03   \n",
                        "max    1.239139e+06                 23.304372  1.557073e+06   \n",
                        "\n",
                        "       20-29 y/o % of total pop         30-39  30-39 y/o % of total pop  ...  \\\n",
                        "count               3140.000000  3.140000e+03               3140.000000  ...   \n",
                        "mean                  12.283979  1.391649e+04                 11.751535  ...   \n",
                        "std                    3.126297  4.899095e+04                  1.696599  ...   \n",
                        "min                    0.000000  1.100000e+01                  6.092789  ...   \n",
                        "25%                   10.496774  1.232750e+03                 10.689322  ...   \n",
                        "50%                   11.772649  3.000500e+03                 11.580861  ...   \n",
                        "75%                   13.182260  8.314250e+03                 12.639379  ...   \n",
                        "max                   37.570198  1.501844e+06                 22.225129  ...   \n",
                        "\n",
                        "         COPD_number  diabetes_prevalence  diabetes_Lower 95% CI  \\\n",
                        "count    3140.000000          3140.000000            3140.000000   \n",
                        "mean     5827.242357            13.073503              12.088089   \n",
                        "std     15720.551934             2.724351               2.622948   \n",
                        "min         7.000000             6.100000               5.500000   \n",
                        "25%       815.000000            11.200000              10.300000   \n",
                        "50%      1963.500000            12.800000              11.800000   \n",
                        "75%      4727.000000            14.800000              13.700000   \n",
                        "max    434075.000000            25.600000              24.200000   \n",
                        "\n",
                        "       diabetes_Upper 95% CI  diabetes_number  CKD_prevalence  \\\n",
                        "count            3140.000000      3140.000000     3140.000000   \n",
                        "mean               14.053726      9326.577707        3.446242   \n",
                        "std                 2.824828     29754.601185        0.568059   \n",
                        "min                 6.700000        11.000000        1.800000   \n",
                        "25%                12.100000      1187.750000        3.100000   \n",
                        "50%                13.800000      2743.000000        3.400000   \n",
                        "75%                15.900000      6679.250000        3.800000   \n",
                        "max                27.000000    952335.000000        6.200000   \n",
                        "\n",
                        "       CKD_Lower 95% CI  CKD_Upper 95% CI     CKD_number  Urban_rural_code  \n",
                        "count       3140.000000       3140.000000    3140.000000       3140.000000  \n",
                        "mean           3.207516          3.710478    2466.234076          4.635350  \n",
                        "std            0.527740          0.613069    7730.422067          1.510447  \n",
                        "min            1.700000          1.900000       3.000000          1.000000  \n",
                        "25%            2.900000          3.300000     314.750000          3.000000  \n",
                        "50%            3.200000          3.700000     718.000000          5.000000  \n",
                        "75%            3.500000          4.100000    1776.250000          6.000000  \n",
                        "max            5.800000          6.600000  237766.000000          6.000000  \n",
                        "\n",
                        "[8 rows x 106 columns]\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "RangeIndex: 3140 entries, 0 to 3139\n",
                        "Columns: 108 entries, fips to Urban_rural_code\n",
                        "dtypes: float64(61), int64(45), object(2)\n",
                        "memory usage: 2.6+ MB\n",
                        "info: None\n"
                    ]
                }
            ],
            "source": [
                "# Check for missing values in the dataset\n",
                "print(data.isnull().any())\n",
                "\n",
                "# Get the shape of the dataset (number of rows and columns)\n",
                "print(\"shape:\", data.shape)\n",
                "\n",
                "# Get a summary of the dataset\n",
                "print(\"describe:\", data.describe())\n",
                "\n",
                "# Get information about the dataset, including data types and non-null counts\n",
                "print(\"info:\", data.info())\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "Index(['TOT_POP', '0-9', '0-9 y/o % of total pop', '19-Oct',\n",
                            "       '10-19 y/o % of total pop', '20-29', '20-29 y/o % of total pop',\n",
                            "       '30-39', '30-39 y/o % of total pop', '40-49',\n",
                            "       '40-49 y/o % of total pop', '50-59', '50-59 y/o % of total pop',\n",
                            "       '60-69', '60-69 y/o % of total pop', '70-79',\n",
                            "       '70-79 y/o % of total pop', '80+', '80+ y/o % of total pop',\n",
                            "       'White-alone pop', '% White-alone', 'Black-alone pop', '% Black-alone',\n",
                            "       'Native American/American Indian-alone pop', '% NA/AI-alone',\n",
                            "       'Asian-alone pop', '% Asian-alone',\n",
                            "       'Hawaiian/Pacific Islander-alone pop', '% Hawaiian/PI-alone',\n",
                            "       'Two or more races pop', '% Two or more races', 'POP_ESTIMATE_2018',\n",
                            "       'N_POP_CHG_2018',\n",
                            "       'Percent of adults with less than a high school diploma 2014-18',\n",
                            "       'Percent of adults with a high school diploma only 2014-18',\n",
                            "       'Percent of adults completing some college or associate's degree 2014-18',\n",
                            "       'Percent of adults with a bachelor's degree or higher 2014-18',\n",
                            "       'POVALL_2018', 'PCTPOVALL_2018', 'PCTPOV017_2018', 'PCTPOV517_2018',\n",
                            "       'MEDHHINC_2018', 'Unemployment_rate_2018',\n",
                            "       'Active Physicians per 100000 Population 2018 (AAMC)',\n",
                            "       'Total Active Patient Care Physicians per 100000 Population 2018 (AAMC)',\n",
                            "       'Active Primary Care Physicians per 100000 Population 2018 (AAMC)',\n",
                            "       'Active Patient Care Primary Care Physicians per 100000 Population 2018 (AAMC)',\n",
                            "       'Active General Surgeons per 100000 Population 2018 (AAMC)',\n",
                            "       'Active Patient Care General Surgeons per 100000 Population 2018 (AAMC)',\n",
                            "       'Total nurse practitioners (2019)', 'Total physician assistants (2019)',\n",
                            "       'Total Hospitals (2019)', 'Internal Medicine Primary Care (2019)',\n",
                            "       'Family Medicine/General Practice Primary Care (2019)',\n",
                            "       'Total Specialist Physicians (2019)', 'ICU Beds_x',\n",
                            "       'Population Aged 60+', 'Percent of Population Aged 60+',\n",
                            "       'county_pop2018_18 and older', 'anycondition_prevalence',\n",
                            "       'anycondition_number', 'Obesity_prevalence', 'Obesity_number',\n",
                            "       'Heart disease_prevalence', 'Heart disease_number', 'COPD_prevalence',\n",
                            "       'COPD_number', 'diabetes_prevalence', 'diabetes_Lower 95% CI',\n",
                            "       'diabetes_Upper 95% CI', 'diabetes_number', 'CKD_prevalence',\n",
                            "       'CKD_number'],\n",
                            "      dtype='object')"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#dropping all columns that dont relate to heart disease\n",
                "columns_to_drop = ['fips', 'COUNTY_NAME', 'STATE_NAME', 'STATE_FIPS', 'CNTY_FIPS', \n",
                "    'GQ_ESTIMATES_2018', 'R_birth_2018', 'R_death_2018', 'R_NATURAL_INC_2018', \n",
                "    'R_INTERNATIONAL_MIG_2018', 'R_DOMESTIC_MIG_2018', 'R_NET_MIG_2018', \n",
                "    'Less than a high school diploma 2014-18', 'High school diploma only 2014-18', \n",
                "    'Some college or associate\\'s degree 2014-18', 'Bachelor\\'s degree or higher 2014-18', \n",
                "    'CI90LBINC_2018', 'CI90UBINC_2018', 'Civilian_labor_force_2018', 'Employed_2018', \n",
                "    'Unemployed_2018', 'Median_Household_Income_2018', 'Med_HH_Income_Percent_of_State_Total_2018', \n",
                "    'anycondition_Lower 95% CI', 'anycondition_Upper 95% CI', 'Obesity_Lower 95% CI', \n",
                "    'Obesity_Upper 95% CI', 'Heart disease_Lower 95% CI', 'Heart disease_Upper 95% CI', \n",
                "    'COPD_Lower 95% CI', 'COPD_Upper 95% CI', 'CKD_Lower 95% CI', 'CKD_Upper 95% CI', \n",
                "    'Total Population','Urban_rural_code']\n",
                "\n",
                "# Drop the columns\n",
                "new_data = data.drop(columns=columns_to_drop)\n",
                "\n",
                "new_data.columns\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Linear Regression R^2: 0.982576036412511\n",
                        "Linear Regression MSE: 0.05621341307521175\n",
                        "sqrt_mean_squared_error 0.23709367995628172\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import mean_squared_error, r2_score\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "import numpy as np\n",
                "\n",
                "X = new_data.drop('Heart disease_prevalence', axis=1)\n",
                "y = new_data['Heart disease_prevalence']\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "\n",
                "# Linear Regression Model\n",
                "lr_model = LinearRegression()\n",
                "lr_model.fit(X_train, y_train)\n",
                "y_pred_lr = lr_model.predict(X_test)\n",
                "mse = mean_squared_error(y_test, y_pred_lr)\n",
                "mse_sqrt = np.sqrt(mse)\n",
                "print(\"Linear Regression R^2:\", r2_score(y_test, y_pred_lr))\n",
                "print(\"Linear Regression MSE:\", mse)\n",
                "print(\"sqrt_mean_squared_error\", mse_sqrt)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Lasso Regression R^2: 0.9669677734710564\n",
                        "Lasso Regression MSE: 0.10656898961834123\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.895e+02, tolerance: 7.676e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n"
                    ]
                }
            ],
            "source": [
                "# Lasso Regression Model\n",
                "lasso_model = Lasso(alpha=0.1)  # Adjust alpha as needed\n",
                "lasso_model.fit(X_train, y_train)\n",
                "y_pred_lasso = lasso_model.predict(X_test)\n",
                "print(\"Lasso Regression R^2:\", r2_score(y_test, y_pred_lasso))\n",
                "print(\"Lasso Regression MSE:\", mean_squared_error(y_test, y_pred_lasso))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.895e+02, tolerance: 7.676e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.530e+02, tolerance: 7.676e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.059e+03, tolerance: 7.676e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.386e+03, tolerance: 7.676e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.376e+03, tolerance: 7.676e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.317e+03, tolerance: 7.676e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 640x480 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Plot R^2 for different alpha values in Lasso\n",
                "alphas = [0.1, 0.5, 1.0, 5.0, 10.0, 20.0]\n",
                "r2_scores = []\n",
                "for alpha in alphas:\n",
                "    lasso = Lasso(alpha=alpha)\n",
                "    lasso.fit(X_train, y_train)\n",
                "    r2_scores.append(r2_score(y_test, lasso.predict(X_test)))\n",
                "\n",
                "plt.plot(alphas, r2_scores, marker='o')\n",
                "plt.xlabel('Alpha')\n",
                "plt.ylabel('R^2 Score')\n",
                "plt.title('Lasso Regression R^2 Score vs Alpha')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.308e+02, tolerance: 6.154e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.296e+02, tolerance: 6.194e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.288e+02, tolerance: 6.095e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.325e+02, tolerance: 6.155e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.310e+02, tolerance: 6.101e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.002e+02, tolerance: 6.154e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.005e+02, tolerance: 6.194e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.906e+02, tolerance: 6.095e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.052e+02, tolerance: 6.155e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.075e+02, tolerance: 6.101e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.344e+02, tolerance: 6.154e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.393e+02, tolerance: 6.194e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.299e+02, tolerance: 6.095e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.465e+02, tolerance: 6.155e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.507e+02, tolerance: 6.101e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.062e+03, tolerance: 6.154e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.721e+02, tolerance: 6.194e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+03, tolerance: 6.095e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.099e+03, tolerance: 6.155e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.081e+03, tolerance: 6.101e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.051e+03, tolerance: 6.154e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+03, tolerance: 6.194e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.072e+03, tolerance: 6.095e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.108e+03, tolerance: 6.155e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.822e+02, tolerance: 6.101e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.019e+03, tolerance: 6.154e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+03, tolerance: 6.194e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Best Hyperparameters: {'alpha': 0.1}\n",
                        "Best R^2 Score: 0.9560197045374956\n",
                        "Optimized Lasso Regression R^2: 0.9669677734710564\n",
                        "Optimized Lasso Regression MSE: 0.10656898961834123\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.057e+03, tolerance: 6.095e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.061e+03, tolerance: 6.155e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.483e+02, tolerance: 6.101e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.895e+02, tolerance: 7.676e-01\n",
                        "  model = cd_fast.enet_coordinate_descent(\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.model_selection import GridSearchCV\n",
                "\n",
                "# Hyperparameter tuning for Lasso Regression\n",
                "param_grid = {'alpha': [0.1, 0.5, 1.0, 5.0, 10.0, 20.0]}\n",
                "lasso = Lasso()\n",
                "grid_search = GridSearchCV(estimator=lasso, param_grid=param_grid, scoring='r2', cv=5)\n",
                "grid_search.fit(X_train, y_train)\n",
                "\n",
                "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
                "print(\"Best R^2 Score:\", grid_search.best_score_)\n",
                "\n",
                "# Use the best model for predictions\n",
                "best_lasso = grid_search.best_estimator_\n",
                "y_pred_best_lasso = best_lasso.predict(X_test)\n",
                "print(\"Optimized Lasso Regression R^2:\", r2_score(y_test, y_pred_best_lasso))\n",
                "print(\"Optimized Lasso Regression MSE:\", mean_squared_error(y_test, y_pred_best_lasso))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([ 9.2736614 ,  6.43780735, 12.79480588,  7.59461716,  6.17027735,\n",
                            "        7.06480593,  7.69386395, 12.62916711,  8.4524078 ,  5.46732492,\n",
                            "        8.42535831, 11.79627478,  5.55188552, 10.76002755,  6.98637919,\n",
                            "        8.71832482,  7.11532916,  8.80801429, 10.82489528,  8.87647675,\n",
                            "        9.26403189,  8.72644712,  7.66409607,  9.63848517,  6.66484455,\n",
                            "        5.89861364,  5.26508243,  8.24354041,  8.10950964, 10.37454177,\n",
                            "       11.77542379,  9.49825228,  9.80705661,  8.90815549,  7.11306055,\n",
                            "       10.56769937,  8.72395227,  7.37050349,  8.18056797,  5.69507919,\n",
                            "       10.15543526,  5.67346851,  8.56663737,  8.85953009,  7.11335886,\n",
                            "       10.30010567,  9.56911994,  9.89190464, 10.60654101, 12.90300223,\n",
                            "       11.2211141 , 13.57487285,  6.60704066, 10.08877256,  7.70113544,\n",
                            "        9.76527792,  6.78944968,  6.36067086,  8.99047672,  9.01497789,\n",
                            "        6.19135155, 11.23188937,  9.91986712,  7.19804453,  7.82037628,\n",
                            "        6.78550265,  8.49693893, 10.10654025,  9.50107425,  7.0475988 ,\n",
                            "        7.00509707, 10.65298858,  8.61781262,  9.90593496,  8.0994113 ,\n",
                            "        5.88287759,  8.9448563 ,  7.0808365 ,  9.21962605, 10.66329776,\n",
                            "        9.42795174,  5.33170784,  4.91795537, 10.74201185,  9.10746798,\n",
                            "        4.50124747,  4.95367998,  8.55248609,  8.53775831,  5.35380756,\n",
                            "       11.73284918, 10.06755825,  6.43051001,  8.78593323,  9.74850526,\n",
                            "        7.07135233, 10.95243887, 10.75295718,  7.4924298 ,  8.57047579,\n",
                            "        9.25267319,  8.07548876, 10.27688063,  8.08658735,  9.15249142,\n",
                            "        7.27835527,  9.73250029,  6.75534491,  7.50434745,  7.53107097,\n",
                            "        7.42338978,  8.71117157,  6.06969988, 10.12193863,  8.5243994 ,\n",
                            "        4.08680631,  7.10196286,  4.75144223,  6.03859825, 11.61112051,\n",
                            "       11.82579881, 10.87244786, 12.37633456, 10.11539467,  9.40157456,\n",
                            "        8.45950737,  5.21588297, 11.30373269,  7.22927999,  7.84942393,\n",
                            "        8.25268643,  9.87194315,  7.71052087,  7.92792216, 11.63752774,\n",
                            "        9.87973125, 11.99646799,  7.09882788,  9.61075167,  9.97630337,\n",
                            "       10.31208264,  8.82859988,  5.30715775,  9.54940522,  9.47103209,\n",
                            "        7.76248604,  9.40509345,  8.08901225,  7.90626907,  6.45921906,\n",
                            "       10.22582981,  6.84343133, 11.37214014, 10.97196712,  9.13898987,\n",
                            "        9.84087866,  9.63008171,  9.09352662,  6.64854789,  7.65144694,\n",
                            "        5.5942643 , 11.82398284,  8.62083963,  8.01859816,  9.60984438,\n",
                            "        7.79979832, 10.35382203,  5.32834055, 10.64483723,  9.68023675,\n",
                            "       10.51437411,  7.93758208,  6.61927051, 10.08385315,  9.82496577,\n",
                            "        8.39578803,  7.89383606,  7.13492514,  7.72606219, 11.18063168,\n",
                            "        8.69114288,  9.09322356, 10.02224117,  9.0739467 ,  7.7500908 ,\n",
                            "        7.98491155,  7.20299883,  9.839412  ,  6.0136849 , 10.56698377,\n",
                            "        6.60907261,  8.77164301,  9.97155253, 10.38526656,  8.2375101 ,\n",
                            "        7.22159942,  8.40782262, 11.50762529,  9.75356466, 11.72411785,\n",
                            "        7.74915625,  9.08864085,  4.7631325 , 10.39678938, 10.81117386,\n",
                            "        8.79733672, 11.50118092,  9.51694034,  7.77404313, 10.91577051,\n",
                            "       11.60800395,  8.93083185,  9.35509796,  9.45187005, 10.48658887,\n",
                            "        5.54042934, 11.51518147,  7.34838259,  9.81217182,  6.26859699,\n",
                            "        7.27983542, 10.21355506, 10.28894583,  8.52442995,  8.06289975,\n",
                            "       11.35718764,  8.75093194,  7.63481349, 12.72557452, 10.97912313,\n",
                            "        8.21961378, 10.98632858,  7.55011496,  6.76760379,  8.59010668,\n",
                            "       11.24328464, 10.64456461,  7.72569419,  9.5074198 ,  5.33385477,\n",
                            "        9.08549887,  8.68171888, 11.06270953, 10.64810387,  7.63614877,\n",
                            "       10.02967401,  8.78407396,  7.55210491,  9.12888115,  9.50375361,\n",
                            "       13.02604917,  8.63197353,  8.62801857,  9.1486619 ,  8.57665829,\n",
                            "       10.04545402,  9.92397139,  7.29326186, 10.71073736,  9.94576255,\n",
                            "        9.63141073,  9.09432707,  8.9639828 ,  9.08152091,  9.74505105,\n",
                            "        9.42289449,  7.30636937,  7.61446611, 10.27546113,  9.0846241 ,\n",
                            "        8.21464089,  9.84641733,  7.54883096,  8.96329121,  7.23999512,\n",
                            "        9.12478409,  8.65037623,  9.15242099,  9.31819727,  8.28039703,\n",
                            "        7.29619085,  7.14999222,  9.57777099,  9.79432356,  9.31885161,\n",
                            "        8.59928907,  9.38689528,  8.47554997,  8.57978249,  7.28068602,\n",
                            "        7.62885117,  6.88374446, 12.67381219,  8.96160936,  7.03087767,\n",
                            "        5.41817612,  7.19304984,  5.80587395,  6.50565254,  9.04431135,\n",
                            "        7.36389187, 11.2357198 ,  6.39185605,  8.11148832, 11.1569231 ,\n",
                            "        3.25263479, 10.3849171 ,  4.3253352 ,  6.57106643,  7.55344082,\n",
                            "       10.78491431, 10.43780746,  8.35505231,  8.25383567,  9.34433971,\n",
                            "        6.99017683,  9.52189638,  8.04239057,  9.35528901,  9.25968614,\n",
                            "        9.56853955,  7.36031307,  4.1862983 ,  8.3210727 , 10.50122316,\n",
                            "        8.78901248, 12.59978806, 12.0075721 , 11.4214207 ,  7.73978283,\n",
                            "       10.31098114,  7.74034947,  8.02712797,  8.42445445,  9.62813257,\n",
                            "        8.59005717,  7.73297562,  8.25892939,  7.34332668,  9.84870153,\n",
                            "       11.98754655, 10.88482996,  7.96075037,  9.74707682,  8.11970794,\n",
                            "        8.14898542, 12.07363926, 10.3149843 ,  9.97391682, 10.83093464,\n",
                            "        7.75136993,  6.29409554,  9.98178866,  7.25619012,  5.76305603,\n",
                            "       12.53351991,  9.94744989,  7.6089823 ,  9.03234682,  7.86692322,\n",
                            "       11.67521601,  9.79988962, 10.71960469, 10.64380121, 11.32872583,\n",
                            "        8.05507346,  6.11978804,  8.17006351, 11.2523825 ,  9.32935978,\n",
                            "        7.91170761,  8.19668903,  7.79879225,  8.75690349,  9.0981486 ,\n",
                            "        9.54645186, 10.2008068 ,  9.55811137,  6.07779871, 10.17428878,\n",
                            "        8.71252497,  6.4704004 ,  5.5711788 ,  7.93587025,  6.73133263,\n",
                            "       10.89955484,  8.71515143,  9.38606464,  4.84786726,  5.98692621,\n",
                            "        8.50008888,  9.15905912,  8.7528443 ,  9.61018882,  9.0599081 ,\n",
                            "        8.92307383, 10.11897871,  7.48519662, 12.70431467,  8.10457465,\n",
                            "       10.07649342,  8.93141771,  7.84621034,  9.48264612,  6.18303744,\n",
                            "       10.71183119,  9.68500675,  6.94071293, 10.03495588,  8.27740185,\n",
                            "       10.66568621,  9.47863665,  8.42921651,  8.69243331, 12.31297483,\n",
                            "        4.76587297,  8.26633004,  8.39456426,  9.99797993,  8.55828135,\n",
                            "       12.21855122,  8.9800043 , 10.92262654,  8.30662111,  6.495264  ,\n",
                            "        7.83028277, 10.00878967,  7.92355763,  9.84152534,  7.54137914,\n",
                            "        7.9639863 , 12.70996607,  9.18358022, 11.88380847,  7.77633727,\n",
                            "       10.93903077, 11.19862132,  9.24852062,  5.47907026,  5.17589859,\n",
                            "       11.83187839,  7.98813774,  4.88597478, 12.52910566,  8.06550206,\n",
                            "        6.97873832,  7.16164912, 12.09069084,  9.82102341, 11.48708039,\n",
                            "        8.12119095,  9.59085552, 11.18488175,  9.01716031,  8.83981448,\n",
                            "        7.28541416,  8.07233188,  8.59144011,  4.82626182,  7.77526518,\n",
                            "        8.29242805,  8.57078326,  8.99593155,  7.73079919,  6.55492446,\n",
                            "        7.56720236,  7.48995437,  9.24903067,  9.22061461,  8.705163  ,\n",
                            "        6.51038798,  6.30564729, 11.54721046,  8.51621279,  9.16056265,\n",
                            "        7.52905136,  9.61018444,  7.20092211,  9.92577935,  9.49795383,\n",
                            "        9.25426578, 11.94616154,  8.27999636,  8.55436901,  5.43757842,\n",
                            "        9.52784208,  8.46618647,  7.63599467,  6.7180582 ,  8.18561198,\n",
                            "       10.38362468,  8.16620747,  8.76553585, 10.12618708,  9.80493763,\n",
                            "        5.75825364,  9.64748676, 12.74095402,  6.19669936, 11.12195695,\n",
                            "        8.39771375,  6.38378612,  8.06608176, 11.79792464,  9.35277869,\n",
                            "        5.34851897,  9.64586256,  8.93690116, 10.44257199,  8.9183676 ,\n",
                            "        9.74202539, 10.08282839,  8.09268114, 10.5547334 ,  7.7210223 ,\n",
                            "        8.70617822, 10.20611962,  8.25389058,  7.33290085,  9.68266972,\n",
                            "        8.55698018,  8.98504366,  9.27252941,  9.55961186,  8.66400407,\n",
                            "        7.61397982,  5.7986665 ,  6.05959813,  7.05695819,  5.46879476,\n",
                            "        8.2323282 ,  6.17000237, 10.23048868,  9.27575189,  8.59768997,\n",
                            "        8.36464412,  9.83992637,  7.97260258,  5.35469706,  7.10054081,\n",
                            "        6.15775272,  8.13999844,  8.14351416,  5.31812913,  8.33370062,\n",
                            "        6.14273411,  9.98859936,  7.06757773,  8.57229901, 11.11792649,\n",
                            "        8.82512741, 10.09807811,  7.16982174,  5.75592552,  8.89501053,\n",
                            "        8.68701536,  7.23381943,  9.50262139,  7.88109388,  4.92936453,\n",
                            "       10.13512377,  8.06250048,  6.33500605,  8.56079618,  9.03533049,\n",
                            "        6.7026819 ,  6.68651314,  8.34623907,  8.76908328,  9.77262274,\n",
                            "       11.42915959, 11.84960986, 12.1687841 ,  9.72698772,  8.57234507,\n",
                            "        5.75530611,  6.16626602,  8.49796606,  8.50225475,  9.87902706,\n",
                            "       10.45683952,  9.38456613,  9.32753187,  7.2327041 ,  8.25650116,\n",
                            "       10.02240838, 13.78748705,  8.26582794,  8.26202236,  5.26025825,\n",
                            "        6.3637964 ,  8.99184335,  8.26522129,  7.22370142,  6.98030663,\n",
                            "        9.61864867,  6.83292149,  8.6993813 ,  8.04876046, 10.61219809,\n",
                            "        9.5589613 ,  5.77017441,  8.95974995,  6.59917553,  9.55381245,\n",
                            "        9.09779554,  6.46256911,  7.96799339,  7.88062461,  7.27043877,\n",
                            "        8.29867525,  8.96680493,  6.25936652, 10.32571133,  8.10816343,\n",
                            "       10.45939854, 11.47452117,  7.82742504,  8.79026943,  9.06761281,\n",
                            "        9.71046006,  9.79291093,  5.85367459,  6.2576722 ,  8.27125217,\n",
                            "        8.49437708,  8.33608259,  7.17443992])"
                        ]
                    },
                    "execution_count": 10,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "ridge_model = Ridge()\n",
                "ridge_model.fit(X_train,y_train)\n",
                "y_predict = ridge_model.predict(X_test)\n",
                "\n",
                "y_predict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
                        "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
                        "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
                        "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
                        "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
                        "[CV] END ..........................................alpha=0.1; total time=   0.0s\n",
                        "[CV] END ..........................................alpha=1.0; total time=   0.0s\n",
                        "[CV] END ..........................................alpha=1.0; total time=   0.0s\n",
                        "[CV] END ..........................................alpha=1.0; total time=   0.0s\n",
                        "[CV] END ..........................................alpha=1.0; total time=   0.0s\n",
                        "[CV] END .........................................alpha=10.0; total time=   0.0s\n",
                        "[CV] END ..........................................alpha=1.0; total time=   0.0s\n",
                        "[CV] END .........................................alpha=10.0; total time=   0.0s\n",
                        "[CV] END .........................................alpha=10.0; total time=   0.0s\n",
                        "[CV] END .........................................alpha=10.0; total time=   0.0s[CV] END ........................................alpha=100.0; total time=   0.0s\n",
                        "\n",
                        "[CV] END .........................................alpha=10.0; total time=   0.0s\n",
                        "[CV] END ........................................alpha=100.0; total time=   0.0s\n",
                        "[CV] END ........................................alpha=100.0; total time=   0.0s\n",
                        "[CV] END ........................................alpha=100.0; total time=   0.0s\n",
                        "[CV] END ........................................alpha=100.0; total time=   0.0s\n",
                        "Test MSE: 0.05621929651320332\n",
                        "Test R^2 Score: 0.9825742127764119\n",
                        "sqrt of mse: 0.2371060870437605\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=3.38838e-17): result may not be accurate.\n",
                        "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=5.09206e-17): result may not be accurate.\n",
                        "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=2.79559e-17): result may not be accurate.\n",
                        "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=7.98365e-18): result may not be accurate.\n",
                        "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n",
                        "/home/vscode/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:216: LinAlgWarning: Ill-conditioned matrix (rcond=4.59744e-17): result may not be accurate.\n",
                        "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
                    ]
                }
            ],
            "source": [
                "# Define model\n",
                "model = Ridge()\n",
                "\n",
                "# Define parameter grid\n",
                "param_grid = {\n",
                "    'alpha': [0.1, 1.0, 10.0, 100.0]\n",
                "}\n",
                "\n",
                "# Initialize GridSearchCV\n",
                "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
                "\n",
                "# Fit GridSearchCV\n",
                "grid_search.fit(X_train, y_train)\n",
                "\n",
                "# Retrieve best parameters and model\n",
                "best_params = grid_search.best_params_\n",
                "best_model = grid_search.best_estimator_\n",
                "\n",
                "# Evaluate on test data\n",
                "y_pred = best_model.predict(X_test)\n",
                "test_mse = mean_squared_error(y_test, y_pred)\n",
                "test_r2 = best_model.score(X_test, y_test)\n",
                "sqrt = np.sqrt(test_mse)\n",
                "#print(f\"Best Parameters: {best_params}\")\n",
                "print(f\"Test MSE: {test_mse}\")\n",
                "print(f\"Test R^2 Score: {test_r2}\")\n",
                "print(f\"sqrt of mse: {sqrt}\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.13 64-bit ('3.8.13')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
